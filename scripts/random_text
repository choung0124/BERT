import argparse
import os
import torch
from transformers import BertModel, BertTokenizerFast

parser = argparse.ArgumentParser(description='Extract entities and relationships from input text using a trained model')
parser.add_argument('--model_dir', type=str, help='The directory where the trained model is stored')
parser.add_argument('--text', type=str, help='The input text to extract entities and relationships from')
args = parser.parse_args()

# Load the model
model_dir = args.model_dir
model = BertModel.from_pretrained(model_dir)

# Load the custom head
ner_classifier_state_dict = torch.load(os.path.join(model_dir, 'custom_head.pt'))['ner_classifier']
re_classifier_state_dict = torch.load(os.path.join(model_dir, 'custom_head.pt'))['re_classifier']
model.ner_classifier.load_state_dict(ner_classifier_state_dict)
model.re_classifier.load_state_dict(re_classifier_state_dict)

# Load the tokenizer
tokenizer = BertTokenizerFast.from_pretrained(model_dir)

# Define the input text
text = args.text

# Tokenize the text
tokens = tokenizer(text, truncation=True, padding='max_length', max_length=128, return_tensors='pt')
input_ids = tokens['input_ids'].to(device)
attention_mask = tokens['attention_mask'].to(device)

# Get the predicted labels
with torch.no_grad():
    ner_logits, re_logits = model(input_ids, attention_mask)

ner_labels_idx = ner_logits.argmax(dim=1)
re_labels_idx = re_logits.argmax(dim=1)

# Convert the predicted label indices back to their original labels
idx2ner_label = {idx: label for label, idx in ner_label2idx.items()}
idx2re_label = {idx: label for label, idx in re_label2idx.items()}
ner_labels = [idx2ner_label[idx.item()] if idx.item() != len(idx2ner_label) - 1 else None for idx in ner_labels_idx]
re_labels = [idx2re_label[idx.item()] if idx.item() != len(idx2re_label) - 1 else None for idx in re_labels_idx]

# Extract the entities and relationships from the text based on the predicted labels
entities = []
for i, label in enumerate(ner_labels):
    if label is not None:
        start = tokens.char_to_token(i)
        end = tokens.char_to_token(i + len(label) - 1)
        entities.append({'entityName': label, 'span': {'begin': start, 'end': end}})

relations = []
for i, label in enumerate(re_labels):
    if label is not None:
        subject_span, object_span = None, None
        for j in range(i, -1, -1):
            if ner_labels[j] is not None:
                subject_span = {'begin': tokens.char_to_token(j), 'end': tokens.char_to_token(j + len(ner_labels[j]) - 1)}
                break
        for j in range(i, len(ner_labels)):
            if ner_labels[j] is not None:
                object_span = {'begin': tokens.char_to_token(j), 'end': tokens.char_to_token(j + len(ner_labels[j]) - 1)}
                break
        relations.append({'rel_name': label, 'subjectText': text[tokens.token_to_char(subject_span['begin']):tokens.token_to_char(subject_span['end'])+1], 'objectText': text[tokens.token_to_char(object_span['begin']):tokens.token_to_char(object_span['end'])+1]})

# Print the result
print("Entities:")
for entity in entities:
    print(entity['entityName'], ":", text[tokens.token_to_char(entity['span']['begin']):tokens.token_to_char(entity['span']['end'])+1])
    
print("Relations:")
for relation in relations:
    print(relation['rel_name'], ":", relation['subjectText'], " - ", relation['objectText'])
